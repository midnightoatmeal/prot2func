{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_all = pd.read_csv(\"protein_sequences.csv\")\n",
        "print(f\"Loaded {len(df_all)} protein sequences from CSV.\")\n",
        "df_all.head(10)"
      ],
      "metadata": {
        "id": "gShTYRL6Pf4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def is_enzyme(uniprot_id: str) -> int | None:\n",
        "    \"\"\"\n",
        "    Queries the UniProt API to check if a protein is an enzyme.\n",
        "    Returns 1 if it is, 0 if not, and None if an error occurs.\n",
        "    \"\"\"\n",
        "    url = f\"https://rest.uniprot.org/uniprotkb/{uniprot_id}.json\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        if response.status_code != 200:\n",
        "            return None  # Error or not found\n",
        "\n",
        "        data = response.json()\n",
        "\n",
        "        # Check for comments of type 'CATALYTICA ACTIVITY' with a valid EC number\n",
        "        for comment in data.get('comments', []):\n",
        "            if comment.get('commentType') == 'CATALYTIC ACTIVITY':\n",
        "                if 'reaction' in comment and comment['reaction'].get('ecNumber'):\n",
        "                    return 1  # It's an enzyme\n",
        "        return 0  # Not an enzyme\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"API request failed for {uniprot_id}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Let's label the first 2000 samples for a better dataset\n",
        "N_SAMPLES = 2000\n",
        "df_sample = df_all.head(N_SAMPLES).copy()\n",
        "\n",
        "# Loop through the sample DataFrame and apply the labeling function\n",
        "tqdm.pandas(desc=\"Labeling Proteins\")\n",
        "df_sample['is_enzyme'] = df_sample['id'].progress_apply(lambda pid: is_enzyme(pid))\n",
        "\n",
        "# Drop any rows where the API call failed\n",
        "df_labeled = df_sample.dropna(subset=['is_enzyme']).copy()\n",
        "df_labeled['is_enzyme'] = df_labeled['is_enzyme'].astype(int)\n",
        "\n",
        "# Save the labeled data for future use\n",
        "df_labeled.to_csv(\"labeled_protein_data_2000.csv\", index=False)\n",
        "\n",
        "print(f\"\\nFinished labeling. Total labeled samples: {len(df_labeled)}\")\n",
        "print(\"Class distribution:\")\n",
        "print(df_labeled['is_enzyme'].value_counts())"
      ],
      "metadata": {
        "id": "r24Excx_Pf2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Define the 20 standard amino acids\n",
        "AMINO_ACIDS = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
        "\n",
        "def aa_composition(sequence: str) -> list[float]:\n",
        "    \"\"\"Calculates the frequency of each standard amino acid in a sequence.\"\"\"\n",
        "    count = Counter(sequence)\n",
        "    total = len(sequence)\n",
        "    # Handle cases where a sequence might be empty or invalid\n",
        "    if total == 0:\n",
        "        return [0.0] * len(AMINO_ACIDS)\n",
        "    return [count.get(aa, 0) / total for aa in AMINO_ACIDS]\n",
        "\n",
        "# Apply the feature engineering function to our labeled data\n",
        "df_features = df_labeled.copy()\n",
        "aa_features = df_features[\"sequence\"].apply(lambda seq: pd.Series(aa_composition(seq), index=AMINO_ACIDS))\n",
        "df_features = pd.concat([df_features, aa_features], axis=1)\n",
        "\n",
        "# --- Exploratory Data Analysis ---\n",
        "# Visualize the class distribution\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x=\"is_enzyme\", data=df_features)\n",
        "plt.title(\"Class Distribution (0: Non-Enzyme, 1: Enzyme)\")\n",
        "plt.xlabel(\"Is Enzyme\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "# Visualize the average composition for each class\n",
        "avg_comp = df_features.groupby(\"is_enzyme\")[AMINO_ACIDS].mean().T\n",
        "avg_comp.plot(kind=\"bar\", figsize=(15, 5), title=\"Average Amino Acid Composition by Class\")\n",
        "plt.xlabel(\"Amino Acid\")\n",
        "plt.ylabel(\"Average Frequency\")\n",
        "plt.legend([\"Non-Enzyme\", \"Enzyme\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7YDdM_YePf0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df_features[AMINO_ACIDS]\n",
        "y = df_features[\"is_enzyme\"]\n",
        "\n",
        "# Create a stratified train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Testing set shape: {X_test.shape}\")"
      ],
      "metadata": {
        "id": "tO5Q8NMTPfxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"--- Improved Logistic Regression ---\")\n",
        "# Use class_weight='balanced' to handle the imbalanced data\n",
        "lr_model = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_lr))"
      ],
      "metadata": {
        "id": "OS9bGY46PfvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchmetrics\n",
        "\n",
        "print(\"\\n--- Improved PyTorch Neural Network ---\")\n",
        "\n",
        "# Convert data to PyTorch Tensors\n",
        "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Create TensorDatasets and DataLoaders\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# Define the Neural Network\n",
        "class EnzymeClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(20, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.out = nn.Linear(32, 2) # Output 2 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.out(x)\n",
        "\n",
        "# Calculate class weights for the loss function\n",
        "class_counts = y_train.value_counts().sort_index()\n",
        "weights = 1. / torch.tensor(class_counts.values, dtype=torch.float32)\n",
        "weights = weights / weights.sum()\n",
        "\n",
        "# Instantiate model, loss, and optimizer\n",
        "nn_model = EnzymeClassifier()\n",
        "loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
        "optimizer = torch.optim.Adam(nn_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    nn_model.train()\n",
        "    for xb, yb in train_loader:\n",
        "        pred = nn_model(xb)\n",
        "        loss = loss_fn(pred, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "      print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
        "precision = torchmetrics.Precision(task=\"multiclass\", num_classes=2)\n",
        "recall = torchmetrics.Recall(task=\"multiclass\", num_classes=2)\n",
        "\n",
        "nn_model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.inference_mode():\n",
        "    for xb, yb in test_loader:\n",
        "        logits = nn_model(xb)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        all_preds.append(preds)\n",
        "        all_labels.append(yb)\n",
        "\n",
        "all_preds = torch.cat(all_preds)\n",
        "all_labels = torch.cat(all_labels)\n",
        "\n",
        "print(\"\\nPyTorch Model Test Metrics:\")\n",
        "print(f\"Accuracy:  {accuracy(all_preds, all_labels):.4f}\")\n",
        "print(f\"Precision: {precision(all_preds, all_labels):.4f} (for class 1)\")\n",
        "print(f\"Recall:    {recall(all_preds, all_labels):.4f} (for class 1)\")"
      ],
      "metadata": {
        "id": "RccEFt5aPftO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "50Mm4rATPfpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zaGqMLZtPfnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K7fhoh88Pfjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e7CecpsyPfe6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
